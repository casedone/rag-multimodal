{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85029350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55536df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pisek/miniconda3/envs/rag-multimodal/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-08-04 09:44:45,199 - src.milvus_store - INFO - Logging to file: logs/milvus_store.log\n",
      "2025-08-04 09:44:45,199 - src.index - INFO - Logging to file: logs/index.log\n"
     ]
    }
   ],
   "source": [
    "from src.index import process_and_index_directory, process_file, get_chunker, get_document_converter\n",
    "from src.config import ConfigLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a95ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2408.09869v5 copy.pdf', '.DS_Store']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dir = \"./doc_folder_1\"\n",
    "\n",
    "os.listdir(doc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbcfcf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigLoader(\"../config.yaml\")\n",
    "chunker = get_chunker(config=config)\n",
    "pdf_pipeline_options = config.get_pdf_pipeline_options()\n",
    "converter = get_document_converter(pdf_pipeline_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a807cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(doc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381da477",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = process_file(f\"{doc_dir}/{files[0]}\", converter=converter, chunker=chunker, namespace=\"CaseDoneDemo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec99c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d74717e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Doc: doc_folder_1/2408.09869v5 copy.pdf, Page no: 1 =============\n",
      "Docling Technical Report\n",
      "Version 1.0\n",
      "Christoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\n",
      "AI4K Group, IBM Research RÂ¨ uschlikon, Switzerland\n",
      "\n",
      "============= Doc: doc_folder_1/2408.09869v5 copy.pdf, Page no: 1 =============\n",
      "Abstract\n",
      "This technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.\n",
      "\n",
      "============= Doc: doc_folder_1/2408.09869v5 copy.pdf, Page no: 1 =============\n",
      "1 Introduction\n",
      "Converting PDF documents back into a machine-processable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which discards most structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, cloud offerings [3] and most recently, multi-modal vision-language models. As of today, only a handful of open-source tools cover PDF conversion, leaving a significant feature and quality gap to proprietary solutions.\n",
      "With Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.\n",
      "Here is what Docling delivers today:\n",
      "- Converts PDF documents to JSON or Markdown format, stable and lightning fast\n",
      "- Understands detailed page layout, reading order, locates figures and recovers table structures\n",
      "- Extracts metadata from the document, such as title, authors, references and language\n",
      "- Optionally applies OCR, e.g. for scanned PDFs\n",
      "- Can be configured to be optimal for batch-mode (i.e high throughput, low time-to-solution) or interactive mode (compromise on efficiency, low time-to-solution)\n",
      "- Can leverage different accelerators (GPU, MPS, etc).\n",
      "\n",
      "============= Doc: doc_folder_1/2408.09869v5 copy.pdf, Page no: 2 =============\n",
      "2 Getting Started\n",
      "To use Docling, you can simply install the docling package from PyPI. Documentation and examples are available in our GitHub repository at github.com/DS4SD/docling. All required model assets 1 are downloaded to a local huggingface datasets cache on first use, unless you choose to pre-install the model assets in advance.\n",
      "Docling provides an easy code interface to convert PDF documents from file system, URLs or binary streams, and retrieve the output in either JSON or Markdown format. For convenience, separate methods are offered to convert single documents or batches of documents. A basic usage example is illustrated below. Further examples are available in the Doclign code repository.\n",
      "```\n",
      "from docling.document_converter import DocumentConverter Large\n",
      "```\n",
      "```\n",
      "source = \"https://arxiv.org/pdf/2206.01062\" # PDF path or URL converter = DocumentConverter() result = converter.convert_single(source) print(result.render_as_markdown()) # output: \"## DocLayNet: A Human -Annotated Dataset for Document -Layout Analysis [...]\"\n",
      "```\n",
      "Optionally, you can configure custom pipeline features and runtime options, such as turning on or off features (e.g. OCR, table structure recognition), enforcing limits on the input document size, and defining the budget of CPU threads. Advanced usage examples and options are documented in the README file. Docling also provides a Dockerfile to demonstrate how to install and run it inside a container.\n",
      "\n",
      "============= Doc: doc_folder_1/2408.09869v5 copy.pdf, Page no: 2 =============\n",
      "3 Processing pipeline\n",
      "Docling implements a linear pipeline of operations, which execute sequentially on each given document (see Fig. 1). Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support downstream operations. Then, the standard model pipeline applies a sequence of AI models independently on every page in the document to extract features and content, such as layout and table structures. Finally, the results from all pages are aggregated and passed through a post-processing stage, which augments metadata, detects the document language, infers reading-order and eventually assembles a typed document object which can be serialized to JSON or Markdown.\n",
      "\n",
      "============= Doc: doc_folder_1/2408.09869v5 copy.pdf, Page no: 2 =============\n",
      "3.1 PDF backends\n",
      "Two basic requirements to process PDF documents in our pipeline are a) to retrieve all text content and their geometric coordinates on each page and b) to render the visual representation of each page as it would appear in a PDF viewer. Both these requirements are encapsulated in Docling's PDF backend interface. While there are several open-source PDF parsing libraries available for python, we faced major obstacles with all of them for different reasons, among which were restrictive\n",
      "1 see huggingface.co/ds4sd/docling-models/\n",
      "Figure 1: Sketch of Docling's default processing pipeline. The inner part of the model pipeline is easily customizable and extensible.\n",
      "\n",
      "<!--<annotation kind=\"description\">-->The image depicts a flowchart illustrating the process of extracting data from a PDF document. It begins with a PDF file that is parsed into individual PDF pages. These pages then enter a model pipeline that consists of three stages: OCR (Optical Character Recognition), Layout Analysis, and Table Structure detection. Each stage processes the pages to extract textual information, analyze the layout, and recognize table structures, respectively. After passing through this pipeline, the results are assembled and undergo document post-processing. The final step in the process involves serializing the processed data into either JSON or Markdown format for use in other applications.<!--<annotation/>-->\n",
      "licensing (e.g. pymupdf [7]), poor speed or unrecoverable quality issues, such as merged text cells across far-apart text tokens or table columns (pypdfium, PyPDF) [15, 14].\n",
      "We therefore decided to provide multiple backend choices, and additionally open-source a custombuilt PDF parser, which is based on the low-level qpdf [4] library. It is made available in a separate package named docling-parse and powers the default PDF backend in Docling. As an alternative, we provide a PDF backend relying on pypdfium , which may be a safe backup choice in certain cases, e.g. if issues are seen with particular font encodings.\n",
      "\n",
      "============= Doc: doc_folder_1/2408.09869v5 copy.pdf, Page no: 3 =============\n",
      "3.2 AI models\n",
      "As part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on huggingface) and a separate package for the inference code as docling-ibm-models . Both models are also powering the open-access deepsearch-experience, our cloud-native service for knowledge exploration tasks.\n",
      "\n",
      "============= Doc: doc_folder_1/2408.09869v5 copy.pdf, Page no: 3 =============\n",
      "Layout Analysis Model\n",
      "Our layout analysis model is an object-detector which predicts the bounding-boxes and classes of various elements on the image of a given page. Its architecture is derived from RT-DETR [16] and re-trained on DocLayNet [13], our popular human-annotated dataset for document-layout analysis, among other proprietary datasets. For inference, our implementation relies on the onnxruntime [5].\n",
      "The Docling pipeline feeds page images at 72 dpi resolution, which can be processed on a single CPU with sub-second latency. All predicted bounding-box proposals for document elements are post-processed to remove overlapping proposals based on confidence and size, and then intersected with the text tokens in the PDF to group them into meaningful and complete units such as paragraphs, section titles, list items, captions, figures or tables.\n",
      "\n",
      "============= Doc: doc_folder_1/2408.09869v5 copy.pdf, Page no: 3 =============\n",
      "Table Structure Recognition\n",
      "The TableFormer model [12], first published in 2022 and since refined with a custom structure token language [9], is a vision-transformer model for table structure recovery. It can predict the logical row and column structure of a given table based on an input image, and determine which table cells belong to column headers, row headers or the table body. Compared to earlier approaches, TableFormer handles many characteristics of tables, such as partial or no borderlines, empty cells, rows or columns, cell spans and hierarchy both on column-heading or row-heading level, tables with inconsistent indentation or alignment and other complexities. For inference, our implementation relies on PyTorch [2].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(\"============= Doc: {}, Page no: {} =============\".format(doc.metadata[\"source\"], doc.metadata[\"page_no\"]))\n",
    "    print(doc.page_content)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb5fe71",
   "metadata": {},
   "source": [
    "# Processing whole folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "666a1edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.set(\"database\", \"collection_name\", \"doc_1_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "befe0e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-04 09:44:54,351 - src.index - INFO - Found 1 files to process\n",
      "2025-08-04 09:44:55,462 - src.milvus_store - INFO - Database 'rag_multimodal' already exists.\n",
      "2025-08-04 09:44:55,472 - src.milvus_store - INFO - Collection 'doc_1_db' has been dropped from database 'rag_multimodal'.\n",
      "2025-08-04 09:44:55,585 [DEBUG][_create_connection]: Created new connection using: async-http://localhost:19530 (async_milvus_client.py:599)\n",
      "2025-08-04 09:44:55,587 - src.index - INFO - Processing doc_folder_1/2408.09869v5 copy.pdf...\n",
      "2025-08-04 09:45:02,110 - src.index - INFO - Indexing 9 documents...\n",
      "2025-08-04 09:45:05,443 - src.milvus_store - INFO - Successfully added 9 documents\n"
     ]
    }
   ],
   "source": [
    "process_and_index_directory(\"./doc_folder_1\", drop_existing=True, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0d91096",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.set(\"database\", \"collection_name\", \"doc_2_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f472bdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-04 09:45:05,474 - src.index - INFO - Found 1 files to process\n",
      "2025-08-04 09:45:06,109 - src.milvus_store - INFO - Database 'rag_multimodal' already exists.\n",
      "2025-08-04 09:45:06,123 - src.milvus_store - INFO - Collection 'doc_2_db' has been dropped from database 'rag_multimodal'.\n",
      "2025-08-04 09:45:06,140 [DEBUG][_create_connection]: Created new connection using: async-http://localhost:19530 (async_milvus_client.py:599)\n",
      "2025-08-04 09:45:06,141 - src.index - INFO - Processing doc_folder_2/seizing-the-agentic-ai-advantage.pdf...\n",
      "/Users/pisek/miniconda3/envs/rag-multimodal/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/pisek/miniconda3/envs/rag-multimodal/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/pisek/miniconda3/envs/rag-multimodal/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
      "2025-08-04 09:45:59,275 - src.index - INFO - Indexing 51 documents...\n",
      "2025-08-04 09:46:03,475 - src.milvus_store - INFO - Successfully added 51 documents\n"
     ]
    }
   ],
   "source": [
    "process_and_index_directory(\"./doc_folder_2\", drop_existing=True, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ea391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
